{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af14b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸ” DETR & GroundingDINO Evaluation on RSUD Dataset\n",
      "======================================================================\n",
      "\n",
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060\n",
      "\n",
      "ðŸ“ Dataset:\n",
      "  Images: F:\\skills-copilot-codespaces-vscode\\thesis\\rsuddataset\\rsud20k\\images\\val\n",
      "  Labels: F:\\skills-copilot-codespaces-vscode\\thesis\\rsuddataset\\rsud20k\\labels\\val\n",
      "  Classes: 13\n",
      "  Output: F:\\skills-copilot-codespaces-vscode\\thesis\\checkpoints\\detr_gdino_eval\n",
      "\n",
      "ðŸ“‚ Loading validation images...\n",
      "  Found 1004 validation images\n",
      "\n",
      "ðŸ¤– Model Availability:\n",
      "  DETR: âŒ Not found (F:\\skills-copilot-codespaces-vscode\\thesis\\checkpoints\\detr_best.pth)\n",
      "  GroundingDINO: âŒ Not found (F:\\skills-copilot-codespaces-vscode\\thesis\\all code\\gdino)\n",
      "\n",
      "âš ï¸ No trained models found!\n",
      "\n",
      "To train models:\n",
      "  â€¢ DETR: Run detr.ipynb (WARNING: 75-150 hours training time)\n",
      "  â€¢ GroundingDINO: Already pretrained, just needs proper setup\n",
      "\n",
      "ðŸ’¡ RECOMMENDATION: Use YOLO model which is already trained!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\skills-copilot-codespaces-vscode\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ” DETR & GroundingDINO Evaluation on RSUD Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ----------------------------\n",
    "# GPU Check\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# RSUD Dataset Configuration\n",
    "# ----------------------------\n",
    "BASE_PATH = Path(r\"F:\\skills-copilot-codespaces-vscode\\thesis\\rsuddataset\\rsud20k\")\n",
    "VAL_IMAGE_DIR = BASE_PATH / \"images\" / \"val\"\n",
    "VAL_LABEL_DIR = BASE_PATH / \"labels\" / \"val\"\n",
    "OUTPUT_DIR = Path(r\"F:\\skills-copilot-codespaces-vscode\\thesis\\checkpoints\\detr_gdino_eval\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# RSUD class names (13 classes)\n",
    "CLASS_NAMES = [\n",
    "    'Dilarang Berhenti',      # 0\n",
    "    'Dilarang Parkir',        # 1\n",
    "    'Dilarang Masuk',         # 2\n",
    "    'Bahaya',                 # 3\n",
    "    'Lampu Lalu Lintas Merah',# 4\n",
    "    'Batas Kecepatan',        # 5\n",
    "    'Wajib',                  # 6\n",
    "    'Larangan Belok',         # 7\n",
    "    'Zona Pejalan Kaki',      # 8\n",
    "    'Petunjuk Arah',          # 9\n",
    "    'Rambu Informasi',        # 10\n",
    "    'Hati-hati',              # 11\n",
    "    'Zona Khusus'             # 12\n",
    "]\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Model paths\n",
    "DETR_WEIGHTS = Path(r\"F:\\skills-copilot-codespaces-vscode\\thesis\\checkpoints\\detr_best.pth\")\n",
    "GDINO_DIR = Path(r\"F:\\skills-copilot-codespaces-vscode\\thesis\\all code\\gdino\")\n",
    "\n",
    "# Evaluation settings\n",
    "VIS_EVERY_N = 50          # Save visualization every N images\n",
    "SCORE_THRES = 0.25        # Detection confidence threshold\n",
    "IOU_THRESHOLD = 0.5       # IoU threshold for matching predictions to ground truth\n",
    "\n",
    "print(f\"\\nðŸ“ Dataset:\")\n",
    "print(f\"  Images: {VAL_IMAGE_DIR}\")\n",
    "print(f\"  Labels: {VAL_LABEL_DIR}\")\n",
    "print(f\"  Classes: {NUM_CLASSES}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Helper Functions\n",
    "# ----------------------------\n",
    "def yolo_to_xyxy(yolo_box, img_w, img_h):\n",
    "    \"\"\"Convert YOLO [x_center, y_center, width, height] (normalized) to [x1, y1, x2, y2] (absolute)\"\"\"\n",
    "    x_center, y_center, width, height = yolo_box\n",
    "    x1 = (x_center - width / 2) * img_w\n",
    "    y1 = (y_center - height / 2) * img_h\n",
    "    x2 = (x_center + width / 2) * img_w\n",
    "    y2 = (y_center + height / 2) * img_h\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def xyxy_to_xywh(box):\n",
    "    \"\"\"Convert [x1, y1, x2, y2] to [x, y, width, height]\"\"\"\n",
    "    x1, y1, x2, y2 = box\n",
    "    return [x1, y1, x2 - x1, y2 - y1]\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate IoU between two boxes in [x1, y1, x2, y2] format\"\"\"\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "    \n",
    "    inter_x_min = max(x1_min, x2_min)\n",
    "    inter_y_min = max(y1_min, y2_min)\n",
    "    inter_x_max = min(x1_max, x2_max)\n",
    "    inter_y_max = min(y1_max, y2_max)\n",
    "    \n",
    "    inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)\n",
    "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def load_yolo_annotations(label_path, img_w, img_h):\n",
    "    \"\"\"Load YOLO format annotations and convert to [x1, y1, x2, y2] format\"\"\"\n",
    "    annotations = []\n",
    "    if not os.path.exists(label_path):\n",
    "        return annotations\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                cls_id = int(parts[0])\n",
    "                x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                box = yolo_to_xyxy([x_center, y_center, width, height], img_w, img_h)\n",
    "                annotations.append({'class': cls_id, 'box': box})\n",
    "    return annotations\n",
    "\n",
    "# ----------------------------\n",
    "# Load validation images\n",
    "# ----------------------------\n",
    "print(\"\\nðŸ“‚ Loading validation images...\")\n",
    "val_images = sorted([f for f in os.listdir(VAL_IMAGE_DIR) if f.endswith(('.jpg', '.png'))])\n",
    "print(f\"  Found {len(val_images)} validation images\")\n",
    "\n",
    "# ----------------------------\n",
    "# Image preprocessing for models\n",
    "# ----------------------------\n",
    "def prepare_image_for_detr(img_bgr):\n",
    "    \"\"\"Prepare image for DETR model\"\"\"\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    pil = Image.fromarray(img_rgb)\n",
    "    # DETR expects 800x800\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((800, 800)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(pil).to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# Check if models exist\n",
    "# ----------------------------\n",
    "detr_available = DETR_WEIGHTS.exists()\n",
    "gdino_available = GDINO_DIR.exists() and (GDINO_DIR / \"groundingdino\").exists()\n",
    "\n",
    "print(f\"\\nðŸ¤– Model Availability:\")\n",
    "print(f\"  DETR: {'âœ… Available' if detr_available else 'âŒ Not found'} ({DETR_WEIGHTS})\")\n",
    "print(f\"  GroundingDINO: {'âœ… Available' if gdino_available else 'âŒ Not found'} ({GDINO_DIR})\")\n",
    "\n",
    "if not detr_available and not gdino_available:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âš ï¸ NO TRAINED MODELS FOUND\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nðŸ“ Current Status:\")\n",
    "    print(\"  â€¢ DETR: Not trained yet\")\n",
    "    print(\"  â€¢ GroundingDINO: Not set up yet\")\n",
    "    print(\"\\nðŸŽ¯ What You Can Do:\")\n",
    "    print(\"\\n  Option 1: Train DETR (NOT RECOMMENDED)\")\n",
    "    print(\"    â€¢ Run: detr.ipynb\")\n",
    "    print(\"    â€¢ Time: 75-150 hours of training\")\n",
    "    print(\"    â€¢ Result: Custom DETR model for RSUD dataset\")\n",
    "    print(\"\\n  Option 2: Setup GroundingDINO (RECOMMENDED)\")\n",
    "    print(\"    â€¢ Already pretrained on many objects\")\n",
    "    print(\"    â€¢ Just needs proper folder setup\")\n",
    "    print(\"    â€¢ Zero-shot detection capability\")\n",
    "    print(\"\\n  Option 3: Use YOLO (BEST OPTION)\")\n",
    "    print(\"    â€¢ Already trained: runs/detect/rsud20k_yolo11/weights/best.pt\")\n",
    "    print(\"    â€¢ Command: yolo val model=F:/skills-copilot-codespaces-vscode/thesis/runs/detect/rsud20k_yolo11/weights/best.pt data=F:/skills-copilot-codespaces-vscode/thesis/rsuddataset/rsud20k/images/data.yaml\")\n",
    "    print(\"    â€¢ Fast, accurate, and ready to use!\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ’¡ For your thesis, YOLO is the best object detection model.\")\n",
    "    print(\"   Compare it with CNN, ViT, and DINOv2 classification models.\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    # ----------------------------\n",
    "    # Load DETR Model (if available)\n",
    "    # ----------------------------\n",
    "    detr_model = None\n",
    "    if detr_available:\n",
    "        print(\"\\nðŸ”„ Loading DETR model...\")\n",
    "        try:\n",
    "            from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "            \n",
    "            # Load model\n",
    "            detr_model = DetrForObjectDetection.from_pretrained(\n",
    "                \"facebook/detr-resnet-50\",\n",
    "                num_labels=NUM_CLASSES,\n",
    "                ignore_mismatched_sizes=True\n",
    "            )\n",
    "            \n",
    "            # Load trained weights\n",
    "            checkpoint = torch.load(DETR_WEIGHTS, map_location=device)\n",
    "            if 'model_state_dict' in checkpoint:\n",
    "                detr_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            else:\n",
    "                detr_model.load_state_dict(checkpoint)\n",
    "            \n",
    "            detr_model.to(device)\n",
    "            detr_model.eval()\n",
    "            print(\"  âœ… DETR model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Failed to load DETR: {e}\")\n",
    "            detr_model = None\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Load GroundingDINO Model (if available)\n",
    "    # ----------------------------\n",
    "    gdino_model = None\n",
    "    if gdino_available:\n",
    "        print(\"\\nðŸ”„ Loading GroundingDINO model...\")\n",
    "        try:\n",
    "            import sys\n",
    "            sys.path.insert(0, str(GDINO_DIR))\n",
    "            \n",
    "            from groundingdino.util.inference import load_model, load_image, predict\n",
    "            \n",
    "            config_path = GDINO_DIR / \"groundingdino\" / \"config\" / \"GroundingDINO_SwinT_OGC.py\"\n",
    "            weights_path = GDINO_DIR / \"weights\" / \"groundingdino_swint_ogc.pth\"\n",
    "            \n",
    "            if config_path.exists() and weights_path.exists():\n",
    "                gdino_model = load_model(str(config_path), str(weights_path))\n",
    "                print(\"  âœ… GroundingDINO model loaded successfully\")\n",
    "            else:\n",
    "                print(f\"  âŒ GroundingDINO files not found\")\n",
    "                print(f\"     Config: {config_path}\")\n",
    "                print(f\"     Weights: {weights_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Failed to load GroundingDINO: {e}\")\n",
    "            gdino_model = None\n",
    "    \n",
    "    if detr_model is None and gdino_model is None:\n",
    "        print(\"\\nâš ï¸ No models could be loaded.\")\n",
    "        print(\"Evaluation cannot proceed without at least one model.\")\n",
    "    else:\n",
    "        # ----------------------------\n",
    "        # Run Evaluation\n",
    "        # ----------------------------\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸ” Running Evaluation...\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Storage for results\n",
    "        detr_results = {\n",
    "            'predictions': [],\n",
    "            'tp': 0, 'fp': 0, 'fn': 0,\n",
    "            'total_gt': 0,\n",
    "            'class_tp': [0] * NUM_CLASSES,\n",
    "            'class_fp': [0] * NUM_CLASSES,\n",
    "            'class_fn': [0] * NUM_CLASSES,\n",
    "            'class_gt': [0] * NUM_CLASSES\n",
    "        }\n",
    "        \n",
    "        gdino_results = {\n",
    "            'predictions': [],\n",
    "            'tp': 0, 'fp': 0, 'fn': 0,\n",
    "            'total_gt': 0,\n",
    "            'class_tp': [0] * NUM_CLASSES,\n",
    "            'class_fp': [0] * NUM_CLASSES,\n",
    "            'class_fn': [0] * NUM_CLASSES,\n",
    "            'class_gt': [0] * NUM_CLASSES\n",
    "        }\n",
    "        \n",
    "        vis_dir = OUTPUT_DIR / \"visualizations\"\n",
    "        vis_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n Processing {len(val_images)} images...\")\n",
    "        \n",
    "        for idx, img_name in enumerate(tqdm(val_images)):\n",
    "            img_path = VAL_IMAGE_DIR / img_name\n",
    "            label_path = VAL_LABEL_DIR / img_name.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "            \n",
    "            # Load image\n",
    "            img_bgr = cv2.imread(str(img_path))\n",
    "            if img_bgr is None:\n",
    "                continue\n",
    "            h, w = img_bgr.shape[:2]\n",
    "            \n",
    "            # Load ground truth\n",
    "            gt_annotations = load_yolo_annotations(label_path, w, h)\n",
    "            detr_results['total_gt'] += len(gt_annotations)\n",
    "            gdino_results['total_gt'] += len(gt_annotations)\n",
    "            for ann in gt_annotations:\n",
    "                detr_results['class_gt'][ann['class']] += 1\n",
    "                gdino_results['class_gt'][ann['class']] += 1\n",
    "            \n",
    "            # ----------------------------\n",
    "            # DETR Inference\n",
    "            # ----------------------------\n",
    "            detr_detections = []\n",
    "            if detr_model is not None:\n",
    "                try:\n",
    "                    input_tensor = prepare_image_for_detr(img_bgr).unsqueeze(0)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        outputs = detr_model(input_tensor)\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    logits = outputs.logits[0]  # [num_queries, num_classes]\n",
    "                    boxes = outputs.pred_boxes[0]  # [num_queries, 4] in cxcywh format\n",
    "                    \n",
    "                    # Convert to probabilities\n",
    "                    probs = logits.softmax(-1)\n",
    "                    scores, labels = probs.max(-1)\n",
    "                    \n",
    "                    # Filter by score and convert boxes\n",
    "                    for score, label, box in zip(scores, labels, boxes):\n",
    "                        if score > SCORE_THRES and label < NUM_CLASSES:\n",
    "                            # Convert from cxcywh (normalized) to xyxy (absolute)\n",
    "                            cx, cy, bw, bh = box.cpu().numpy()\n",
    "                            x1 = (cx - bw/2) * w\n",
    "                            y1 = (cy - bh/2) * h\n",
    "                            x2 = (cx + bw/2) * w\n",
    "                            y2 = (cy + bh/2) * h\n",
    "                            \n",
    "                            detr_detections.append({\n",
    "                                'class': int(label),\n",
    "                                'box': [x1, y1, x2, y2],\n",
    "                                'score': float(score)\n",
    "                            })\n",
    "                    \n",
    "                    detr_results['predictions'].append({\n",
    "                        'image': img_name,\n",
    "                        'detections': detr_detections,\n",
    "                        'ground_truth': gt_annotations\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n  âš ï¸ DETR error on {img_name}: {e}\")\n",
    "            \n",
    "            # ----------------------------\n",
    "            # GroundingDINO Inference\n",
    "            # ----------------------------\n",
    "            gdino_detections = []\n",
    "            if gdino_model is not None:\n",
    "                try:\n",
    "                    # Create text prompt from class names\n",
    "                    text_prompt = \" . \".join(CLASS_NAMES) + \" .\"\n",
    "                    \n",
    "                    # Load image for GroundingDINO\n",
    "                    from groundingdino.util.inference import load_image, predict\n",
    "                    image_source, image_transformed = load_image(str(img_path))\n",
    "                    \n",
    "                    # Run inference\n",
    "                    boxes, logits, phrases = predict(\n",
    "                        model=gdino_model,\n",
    "                        image=image_transformed,\n",
    "                        caption=text_prompt,\n",
    "                        box_threshold=SCORE_THRES,\n",
    "                        text_threshold=0.25,\n",
    "                        device=device\n",
    "                    )\n",
    "                    \n",
    "                    # Convert boxes (normalized cxcywh) to absolute xyxy\n",
    "                    for box, logit, phrase in zip(boxes, logits, phrases):\n",
    "                        cx, cy, bw, bh = box.cpu().numpy()\n",
    "                        x1 = (cx - bw/2) * w\n",
    "                        y1 = (cy - bh/2) * h\n",
    "                        x2 = (cx + bw/2) * w\n",
    "                        y2 = (cy + bh/2) * h\n",
    "                        \n",
    "                        # Map phrase to class\n",
    "                        try:\n",
    "                            class_id = CLASS_NAMES.index(phrase)\n",
    "                        except ValueError:\n",
    "                            class_id = 0  # default\n",
    "                        \n",
    "                        gdino_detections.append({\n",
    "                            'class': class_id,\n",
    "                            'box': [x1, y1, x2, y2],\n",
    "                            'score': float(logit)\n",
    "                        })\n",
    "                    \n",
    "                    gdino_results['predictions'].append({\n",
    "                        'image': img_name,\n",
    "                        'detections': gdino_detections,\n",
    "                        'ground_truth': gt_annotations\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n  âš ï¸ GroundingDINO error on {img_name}: {e}\")\n",
    "            \n",
    "            # ----------------------------\n",
    "            # Match predictions to ground truth (for DETR)\n",
    "            # ----------------------------\n",
    "            if detr_model is not None and len(detr_detections) > 0:\n",
    "                matched_gt = set()\n",
    "                for det in detr_detections:\n",
    "                    matched = False\n",
    "                    for gt_idx, gt in enumerate(gt_annotations):\n",
    "                        if gt_idx in matched_gt:\n",
    "                            continue\n",
    "                        if det['class'] == gt['class']:\n",
    "                            iou = calculate_iou(det['box'], gt['box'])\n",
    "                            if iou >= IOU_THRESHOLD:\n",
    "                                detr_results['tp'] += 1\n",
    "                                detr_results['class_tp'][det['class']] += 1\n",
    "                                matched_gt.add(gt_idx)\n",
    "                                matched = True\n",
    "                                break\n",
    "                    if not matched:\n",
    "                        detr_results['fp'] += 1\n",
    "                        detr_results['class_fp'][det['class']] += 1\n",
    "                \n",
    "                # Count false negatives (unmatched ground truth)\n",
    "                fn_count = len(gt_annotations) - len(matched_gt)\n",
    "                detr_results['fn'] += fn_count\n",
    "            \n",
    "            # ----------------------------\n",
    "            # Match predictions to ground truth (for GroundingDINO)\n",
    "            # ----------------------------\n",
    "            if gdino_model is not None and len(gdino_detections) > 0:\n",
    "                matched_gt = set()\n",
    "                for det in gdino_detections:\n",
    "                    matched = False\n",
    "                    for gt_idx, gt in enumerate(gt_annotations):\n",
    "                        if gt_idx in matched_gt:\n",
    "                            continue\n",
    "                        if det['class'] == gt['class']:\n",
    "                            iou = calculate_iou(det['box'], gt['box'])\n",
    "                            if iou >= IOU_THRESHOLD:\n",
    "                                gdino_results['tp'] += 1\n",
    "                                gdino_results['class_tp'][det['class']] += 1\n",
    "                                matched_gt.add(gt_idx)\n",
    "                                matched = True\n",
    "                                break\n",
    "                    if not matched:\n",
    "                        gdino_results['fp'] += 1\n",
    "                        gdino_results['class_fp'][det['class']] += 1\n",
    "                \n",
    "                fn_count = len(gt_annotations) - len(matched_gt)\n",
    "                gdino_results['fn'] += fn_count\n",
    "            \n",
    "            # ----------------------------\n",
    "            # Visualization\n",
    "            # ----------------------------\n",
    "            if (idx % VIS_EVERY_N) == 0:\n",
    "                vis_img = img_bgr.copy()\n",
    "                \n",
    "                # Draw ground truth (green)\n",
    "                for gt in gt_annotations:\n",
    "                    x1, y1, x2, y2 = map(int, gt['box'])\n",
    "                    cv2.rectangle(vis_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(vis_img, f\"GT:{CLASS_NAMES[gt['class']][:10]}\", \n",
    "                               (x1, max(15, y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "                \n",
    "                # Draw DETR predictions (blue)\n",
    "                if detr_model is not None:\n",
    "                    for det in detr_detections[:10]:  # Top 10\n",
    "                        x1, y1, x2, y2 = map(int, det['box'])\n",
    "                        cv2.rectangle(vis_img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                        cv2.putText(vis_img, f\"D:{det['score']:.2f}\", \n",
    "                                   (x1, max(30, y1-20)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)\n",
    "                \n",
    "                # Draw GroundingDINO predictions (red)\n",
    "                if gdino_model is not None:\n",
    "                    for det in gdino_detections[:10]:  # Top 10\n",
    "                        x1, y1, x2, y2 = map(int, det['box'])\n",
    "                        cv2.rectangle(vis_img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                        cv2.putText(vis_img, f\"G:{det['score']:.2f}\", \n",
    "                                   (x1, max(45, y1-35)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
    "                \n",
    "                cv2.imwrite(str(vis_dir / f\"vis_{idx:04d}.jpg\"), vis_img)\n",
    "        \n",
    "        # ----------------------------\n",
    "        # Calculate Metrics\n",
    "        # ----------------------------\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸ“Š EVALUATION RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        def calculate_metrics(results, model_name):\n",
    "            tp = results['tp']\n",
    "            fp = results['fp']\n",
    "            fn = results['fn']\n",
    "            \n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            print(f\"\\n--- {model_name} ---\")\n",
    "            print(f\"  Total Ground Truth: {results['total_gt']}\")\n",
    "            print(f\"  True Positives: {tp}\")\n",
    "            print(f\"  False Positives: {fp}\")\n",
    "            print(f\"  False Negatives: {fn}\")\n",
    "            print(f\"  Precision: {precision*100:.2f}%\")\n",
    "            print(f\"  Recall: {recall*100:.2f}%\")\n",
    "            print(f\"  F1-Score: {f1:.4f}\")\n",
    "            \n",
    "            # Per-class metrics\n",
    "            print(f\"\\n  Per-Class Results:\")\n",
    "            for i in range(NUM_CLASSES):\n",
    "                if results['class_gt'][i] > 0:\n",
    "                    class_precision = results['class_tp'][i] / (results['class_tp'][i] + results['class_fp'][i]) if (results['class_tp'][i] + results['class_fp'][i]) > 0 else 0\n",
    "                    class_recall = results['class_tp'][i] / results['class_gt'][i] if results['class_gt'][i] > 0 else 0\n",
    "                    print(f\"    {CLASS_NAMES[i][:20]:<20}: P={class_precision*100:5.1f}% R={class_recall*100:5.1f}% (GT={results['class_gt'][i]})\")\n",
    "            \n",
    "            return {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "        \n",
    "        if detr_model is not None:\n",
    "            detr_metrics = calculate_metrics(detr_results, \"DETR\")\n",
    "        \n",
    "        if gdino_model is not None:\n",
    "            gdino_metrics = calculate_metrics(gdino_results, \"GroundingDINO\")\n",
    "        \n",
    "        # ----------------------------\n",
    "        # Save Results\n",
    "        # ----------------------------\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸ’¾ Saving Results...\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        if detr_model is not None:\n",
    "            with open(OUTPUT_DIR / \"detr_results.json\", \"w\") as f:\n",
    "                json.dump(detr_results, f, indent=2)\n",
    "            print(f\"  âœ… DETR results saved to {OUTPUT_DIR / 'detr_results.json'}\")\n",
    "        \n",
    "        if gdino_model is not None:\n",
    "            with open(OUTPUT_DIR / \"gdino_results.json\", \"w\") as f:\n",
    "                json.dump(gdino_results, f, indent=2)\n",
    "            print(f\"  âœ… GroundingDINO results saved to {OUTPUT_DIR / 'gdino_results.json'}\")\n",
    "        \n",
    "        print(f\"  âœ… Visualizations saved to {vis_dir}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"âœ… Evaluation Complete!\")\n",
    "        print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
