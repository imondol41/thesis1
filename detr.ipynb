{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060\n",
      "CUDA Version: 12.8\n",
      "Found 18681 images in F:/skills-copilot-codespaces-vscode/thesis/rsuddataset/rsud20k/images/train\n",
      "Found 1004 images in F:/skills-copilot-codespaces-vscode/thesis/rsuddataset/rsud20k/images/val\n",
      "\n",
      "Dataset loaded:\n",
      "  Train: 18681 images\n",
      "  Val: 1004 images\n",
      "  Classes: 13\n",
      "\n",
      "============================================================\n",
      "DETR Model Setup\n",
      "============================================================\n",
      "‚úì DETR model loaded on cuda\n",
      "‚úì Optimizer: AdamW (lr=1e-4)\n",
      "‚úì Total parameters: 41,504,722\n",
      "‚úì Trainable parameters: 41,282,322\n",
      "============================================================\n",
      "‚úì DETR model loaded on cuda\n",
      "‚úì Optimizer: AdamW (lr=1e-4)\n",
      "‚úì Total parameters: 41,504,722\n",
      "‚úì Trainable parameters: 41,282,322\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------\n",
    "# GPU check\n",
    "# ------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# ------------------------\n",
    "# RSUD Dataset for DETR\n",
    "# ------------------------\n",
    "class RSUDDatasetDETR(Dataset):\n",
    "    \"\"\"RSUD dataset for DETR training\"\"\"\n",
    "    def __init__(self, img_dir, label_dir, transform=None):\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.label_dir = Path(label_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = sorted([f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))])\n",
    "        \n",
    "        # RSUD class names (13 classes)\n",
    "        self.classes = [\n",
    "            'Dilarang Berhenti', 'Dilarang Parkir', 'Dilarang Masuk',\n",
    "            'Bahaya', 'Lampu Lalu Lintas Merah', 'Batas Kecepatan',\n",
    "            'Wajib', 'Larangan Belok', 'Zona Pejalan Kaki',\n",
    "            'Petunjuk Arah', 'Rambu Informasi', 'Hati-hati',\n",
    "            'Zona Khusus'\n",
    "        ]\n",
    "        \n",
    "        print(f\"Found {len(self.image_files)} images in {img_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = self.img_dir / img_name\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Load YOLO format labels\n",
    "        label_name = img_name.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "        label_path = self.label_dir / label_name\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        class_id = int(parts[0])\n",
    "                        x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                        \n",
    "                        # Convert YOLO format (normalized) to DETR format (absolute pixels)\n",
    "                        img_w, img_h = image.size\n",
    "                        x1 = (x_center - width/2) * img_w\n",
    "                        y1 = (y_center - height/2) * img_h\n",
    "                        x2 = (x_center + width/2) * img_w\n",
    "                        y2 = (y_center + height/2) * img_h\n",
    "                        \n",
    "                        boxes.append([x1, y1, x2, y2])\n",
    "                        labels.append(class_id)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([idx])\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# ------------------------\n",
    "# Data Transforms\n",
    "# ------------------------\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.Resize((800, 800)))  # DETR works better with larger images\n",
    "    transforms.append(T.ToTensor())\n",
    "    transforms.append(T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "# ------------------------\n",
    "# Dataset Setup with RSUD paths\n",
    "# ------------------------\n",
    "base_path = \"F:/skills-copilot-codespaces-vscode/thesis/rsuddataset/rsud20k\"\n",
    "\n",
    "train_dataset = RSUDDatasetDETR(\n",
    "    img_dir=f'{base_path}/images/train',\n",
    "    label_dir=f'{base_path}/labels/train',\n",
    "    transform=get_transform(train=True)\n",
    ")\n",
    "\n",
    "val_dataset = RSUDDatasetDETR(\n",
    "    img_dir=f'{base_path}/images/val',\n",
    "    label_dir=f'{base_path}/labels/val',\n",
    "    transform=get_transform(train=False)\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for DETR\"\"\"\n",
    "    images = []\n",
    "    targets = []\n",
    "    for img, target in batch:\n",
    "        images.append(img)\n",
    "        targets.append(target)\n",
    "    return images, targets\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "print(f\"\\nDataset loaded:\")\n",
    "print(f\"  Train: {len(train_dataset)} images\")\n",
    "print(f\"  Val: {len(val_dataset)} images\")\n",
    "print(f\"  Classes: {len(train_dataset.classes)}\")\n",
    "\n",
    "# ------------------------\n",
    "# DETR Model Setup\n",
    "# ------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETR Model Setup\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# DETR expects num_classes + 1 (including background/no-object class)\n",
    "num_classes = 13  # RSUD has 13 classes\n",
    "\n",
    "# Load DETR model\n",
    "# Note: torchvision doesn't have DETR built-in, you need to use transformers library\n",
    "try:\n",
    "    from transformers import DetrForObjectDetection, DetrConfig\n",
    "    \n",
    "    # Initialize DETR model\n",
    "    config = DetrConfig(num_labels=num_classes)\n",
    "    model = DetrForObjectDetection(config)\n",
    "    model.to(device)\n",
    "    print(f\"‚úì DETR model loaded on {device}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö† transformers library not found\")\n",
    "    print(\"Install it with: pip install transformers\")\n",
    "    print(\"\\nAlternative: Use YOLO for object detection\")\n",
    "    print(\"  Your trained YOLO model: runs/detect/rsud20k_yolo11/weights/best.pt\")\n",
    "    model = None\n",
    "\n",
    "# ------------------------\n",
    "# Optimizer & Scheduler\n",
    "# ------------------------\n",
    "if model is not None:\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.AdamW(params, lr=1e-4, weight_decay=1e-4)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "    print(f\"‚úì Optimizer: AdamW (lr=1e-4)\")\n",
    "    print(f\"‚úì Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"‚úì Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ------------------------\n",
    "# Training Loop\n",
    "# ------------------------\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, (images, targets) in enumerate(data_loader):\n",
    "        # Move to device\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(pixel_values=torch.stack(images), labels=targets)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Batch [{i+1}/{len(data_loader)}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    print(f\"Epoch [{epoch+1}] Average Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "# ------------------------\n",
    "# Evaluation\n",
    "# ------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, targets in data_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        outputs = model(pixel_values=torch.stack(images), labels=targets)\n",
    "        running_loss += outputs.loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "# ------------------------\n",
    "# IMPORTANT NOTE FOR TRAINING\n",
    "# ------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚ö†Ô∏è  DETR TRAINING INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"DETR (Detection Transformer) is VERY computationally expensive:\")\n",
    "print(\"  ‚Ä¢ Typical training: 300+ epochs needed for convergence\")\n",
    "print(\"  ‚Ä¢ Each epoch: ~15-30 minutes (on RTX 3060)\")\n",
    "print(\"  ‚Ä¢ Total training time: 75-150 HOURS\")\n",
    "print(\"  ‚Ä¢ Memory: Uses 800x800 images with batch size 2\")\n",
    "print()\n",
    "print(\"For your thesis, you already have:\")\n",
    "print(\"  ‚úÖ YOLO: Fast, accurate object detection (already trained)\")\n",
    "print(\"  ‚úÖ ViT: Classification model (30% accuracy)\")\n",
    "print(\"  ‚úÖ CNN: Baseline classification\")\n",
    "print(\"  ‚úÖ DINOv2: Advanced vision transformer\")\n",
    "print()\n",
    "print(\"RECOMMENDATION:\")\n",
    "print(\"  1. Use your YOLO model for object detection tasks\")\n",
    "print(\"  2. Focus on improving classification models (ViT/CNN/DINOv2)\")\n",
    "print(\"  3. Only train DETR if you need transformer-based detection comparison\")\n",
    "print()\n",
    "print(\"If you want to train DETR anyway, uncomment the training code below:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# ------------------------\n",
    "# Training execution (COMMENTED OUT - Uncomment to train)\n",
    "# ------------------------\n",
    "# WARNING: This will take 75-150 hours to train properly!\n",
    "# Uncomment the code below if you really want to train DETR\n",
    "\n",
    "\"\"\"\n",
    "if model is not None:\n",
    "    num_epochs = 10  # Should be 300+ for good results, using 10 for testing\n",
    "    output_dir = Path(r\"F:\\skills-copilot-codespaces-vscode\\thesis\\checkpoints\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    print(f\"\\nüöÄ Starting DETR training for {num_epochs} epochs...\")\n",
    "    print(\"‚ö†Ô∏è  Note: DETR typically needs 300+ epochs for good results\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_loss = evaluate(model, val_loader, device)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Update learning rate\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), output_dir / \"detr_best.pth\")\n",
    "            print(f\"  ‚úì Saved best model (Val Loss: {val_loss:.4f})\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), output_dir / \"detr_final.pth\")\n",
    "    print(f\"\\n‚úì DETR training completed!\")\n",
    "    print(f\"  Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"  Models saved to: {output_dir.absolute()}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(range(1, num_epochs+1), train_losses, label=\"Train Loss\", marker='o')\n",
    "    ax.plot(range(1, num_epochs+1), val_losses, label=\"Val Loss\", marker='s')\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"DETR Training and Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / \"detr_training_curves.png\", dpi=150)\n",
    "    print(f\"  Training curves saved!\")\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n‚úì DETR notebook setup complete!\")\n",
    "print(\"  To train: Uncomment the training code above\")\n",
    "print(\"  To use YOLO: Load your trained model at runs/detect/rsud20k_yolo11/weights/best.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
