{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5689a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060\n",
      "‚úì Loaded YOLO model from: f:/skills-copilot-codespaces-vscode/thesis/runs/detect/rsud20k_yolo114/weights/best.pt\n",
      "Model classes: {0: 'person', 1: 'rickshaw', 2: 'rickshaw_van', 3: 'auto_rickshaw', 4: 'truck', 5: 'pickup_truck', 6: 'private_car', 7: 'motorcycle', 8: 'bicycle', 9: 'bus', 10: 'micro_bus', 11: 'covered_van', 12: 'human_hauler'}\n",
      "\n",
      "Camera calibration:\n",
      "  Focal length: 1000 pixels\n",
      "  Speed averaging: 5 frames\n",
      "\n",
      "Video Info:\n",
      "  Resolution: 640x360\n",
      "  FPS: 30\n",
      "  Total Frames: 102550\n",
      "  Duration: 3418.3 seconds\n",
      "\n",
      "Detection settings:\n",
      "  Confidence: 0.15\n",
      "  IoU: 0.3\n",
      "  Image size: 1280px\n",
      "\n",
      "Processing video...\n",
      "Press 'q' to stop early\n",
      "\n",
      "‚úì Loaded YOLO model from: f:/skills-copilot-codespaces-vscode/thesis/runs/detect/rsud20k_yolo114/weights/best.pt\n",
      "Model classes: {0: 'person', 1: 'rickshaw', 2: 'rickshaw_van', 3: 'auto_rickshaw', 4: 'truck', 5: 'pickup_truck', 6: 'private_car', 7: 'motorcycle', 8: 'bicycle', 9: 'bus', 10: 'micro_bus', 11: 'covered_van', 12: 'human_hauler'}\n",
      "\n",
      "Camera calibration:\n",
      "  Focal length: 1000 pixels\n",
      "  Speed averaging: 5 frames\n",
      "\n",
      "Video Info:\n",
      "  Resolution: 640x360\n",
      "  FPS: 30\n",
      "  Total Frames: 102550\n",
      "  Duration: 3418.3 seconds\n",
      "\n",
      "Detection settings:\n",
      "  Confidence: 0.15\n",
      "  IoU: 0.3\n",
      "  Image size: 1280px\n",
      "\n",
      "Processing video...\n",
      "Press 'q' to stop early\n",
      "\n",
      "Progress: 0.0% (30/102550)\n",
      "Progress: 0.0% (30/102550)\n",
      "Progress: 0.1% (60/102550)\n",
      "Progress: 0.1% (60/102550)\n",
      "Progress: 0.1% (90/102550)\n",
      "Progress: 0.1% (90/102550)\n",
      "Progress: 0.1% (120/102550) - Objects: 1 - Avg Conf: 0.15 - Avg Dist: 46.7m\n",
      "Progress: 0.1% (120/102550) - Objects: 1 - Avg Conf: 0.15 - Avg Dist: 46.7m\n",
      "Progress: 0.1% (150/102550) - Objects: 1 - Avg Conf: 0.46 - Avg Dist: 44.4m\n",
      "Progress: 0.1% (150/102550) - Objects: 1 - Avg Conf: 0.46 - Avg Dist: 44.4m\n",
      "Progress: 0.2% (180/102550) - Objects: 1 - Avg Conf: 0.73 - Avg Dist: 44.7m\n",
      "Progress: 0.2% (180/102550) - Objects: 1 - Avg Conf: 0.73 - Avg Dist: 44.7m\n",
      "Progress: 0.2% (210/102550) - Objects: 1 - Avg Conf: 0.89 - Avg Dist: 41.7m\n",
      "Progress: 0.2% (210/102550) - Objects: 1 - Avg Conf: 0.89 - Avg Dist: 41.7m\n",
      "Progress: 0.2% (240/102550) - Objects: 1 - Avg Conf: 0.91 - Avg Dist: 41.9m\n",
      "Progress: 0.2% (240/102550) - Objects: 1 - Avg Conf: 0.91 - Avg Dist: 41.9m\n",
      "Progress: 0.3% (270/102550) - Objects: 1 - Avg Conf: 0.91 - Avg Dist: 40.4m\n",
      "Progress: 0.3% (270/102550) - Objects: 1 - Avg Conf: 0.91 - Avg Dist: 40.4m\n",
      "Progress: 0.3% (300/102550) - Objects: 2 - Avg Conf: 0.60 - Avg Dist: 66.5m\n",
      "Progress: 0.3% (300/102550) - Objects: 2 - Avg Conf: 0.60 - Avg Dist: 66.5m\n",
      "Progress: 0.3% (330/102550) - Objects: 3 - Avg Conf: 0.54 - Avg Dist: 65.8m\n",
      "Progress: 0.3% (330/102550) - Objects: 3 - Avg Conf: 0.54 - Avg Dist: 65.8m\n",
      "Progress: 0.4% (360/102550) - Objects: 2 - Avg Conf: 0.59 - Avg Dist: 54.3m\n",
      "Progress: 0.4% (360/102550) - Objects: 2 - Avg Conf: 0.59 - Avg Dist: 54.3m\n",
      "Progress: 0.4% (390/102550) - Objects: 4 - Avg Conf: 0.45 - Avg Dist: 44.5m\n",
      "Progress: 0.4% (390/102550) - Objects: 4 - Avg Conf: 0.45 - Avg Dist: 44.5m\n",
      "Progress: 0.4% (420/102550) - Objects: 4 - Avg Conf: 0.62 - Avg Dist: 49.1m\n",
      "Progress: 0.4% (420/102550) - Objects: 4 - Avg Conf: 0.62 - Avg Dist: 49.1m\n",
      "Progress: 0.4% (450/102550) - Objects: 4 - Avg Conf: 0.71 - Avg Dist: 44.8m\n",
      "Progress: 0.4% (450/102550) - Objects: 4 - Avg Conf: 0.71 - Avg Dist: 44.8m\n",
      "Progress: 0.5% (480/102550) - Objects: 2 - Avg Conf: 0.91 - Avg Dist: 32.0m\n",
      "Progress: 0.5% (480/102550) - Objects: 2 - Avg Conf: 0.91 - Avg Dist: 32.0m\n",
      "Progress: 0.5% (510/102550) - Objects: 4 - Avg Conf: 0.78 - Avg Dist: 24.0m\n",
      "Progress: 0.5% (510/102550) - Objects: 4 - Avg Conf: 0.78 - Avg Dist: 24.0m\n",
      "Progress: 0.5% (540/102550) - Objects: 3 - Avg Conf: 0.69 - Avg Dist: 24.7m\n",
      "Progress: 0.5% (540/102550) - Objects: 3 - Avg Conf: 0.69 - Avg Dist: 24.7m\n",
      "Progress: 0.6% (570/102550) - Objects: 2 - Avg Conf: 0.83 - Avg Dist: 29.4m\n",
      "Progress: 0.6% (570/102550) - Objects: 2 - Avg Conf: 0.83 - Avg Dist: 29.4m\n",
      "Progress: 0.6% (600/102550) - Objects: 2 - Avg Conf: 0.58 - Avg Dist: 60.0m\n",
      "Progress: 0.6% (600/102550) - Objects: 2 - Avg Conf: 0.58 - Avg Dist: 60.0m\n",
      "Progress: 0.6% (630/102550) - Objects: 1 - Avg Conf: 0.91 - Avg Dist: 37.5m\n",
      "Progress: 0.6% (630/102550) - Objects: 1 - Avg Conf: 0.91 - Avg Dist: 37.5m\n",
      "Progress: 0.6% (660/102550) - Objects: 2 - Avg Conf: 0.69 - Avg Dist: 59.2m\n",
      "Progress: 0.6% (660/102550) - Objects: 2 - Avg Conf: 0.69 - Avg Dist: 59.2m\n",
      "Progress: 0.7% (690/102550) - Objects: 3 - Avg Conf: 0.42 - Avg Dist: 63.9m\n",
      "Progress: 0.7% (690/102550) - Objects: 3 - Avg Conf: 0.42 - Avg Dist: 63.9m\n",
      "Progress: 0.7% (720/102550) - Objects: 3 - Avg Conf: 0.31 - Avg Dist: 40.6m\n",
      "Progress: 0.7% (720/102550) - Objects: 3 - Avg Conf: 0.31 - Avg Dist: 40.6m\n",
      "Progress: 0.7% (750/102550) - Objects: 1 - Avg Conf: 0.43 - Avg Dist: 38.2m\n",
      "Progress: 0.7% (750/102550) - Objects: 1 - Avg Conf: 0.43 - Avg Dist: 38.2m\n",
      "Progress: 0.8% (780/102550) - Objects: 1 - Avg Conf: 0.87 - Avg Dist: 38.1m\n",
      "Progress: 0.8% (780/102550) - Objects: 1 - Avg Conf: 0.87 - Avg Dist: 38.1m\n",
      "\n",
      "Stopped by user\n",
      "\n",
      "======================================================================\n",
      "‚úì Video processing complete!\n",
      "======================================================================\n",
      "Total frames processed: 791\n",
      "Total detections: 1510\n",
      "\n",
      "Output files:\n",
      "  Video: f:\\skills-copilot-codespaces-vscode\\thesis\\all code\\runs\\detect\\distance_tracking\\annotated_video.mp4\n",
      "  CSV:   f:\\skills-copilot-codespaces-vscode\\thesis\\all code\\runs\\detect\\distance_tracking\\detections_with_distance.csv\n",
      "\n",
      "Detection Summary by Class:\n",
      "               Detections  Avg Confidence  Avg Distance (m)  Avg Speed (km/h)\n",
      "class                                                                        \n",
      "auto_rickshaw          83            0.30         71.040001            126.11\n",
      "bus                     3            0.20         12.970000              6.80\n",
      "car                  1324            0.70         43.090000            550.26\n",
      "micro_bus              31            0.46         23.150000             46.31\n",
      "motorcycle             41            0.34         77.199997             70.46\n",
      "person                 24            0.27         31.760000             51.06\n",
      "rickshaw                4            0.19         76.970001             38.51\n",
      "\n",
      "Overall Stats:\n",
      "  Average confidence: 0.650\n",
      "  Average distance: 45.0 meters\n",
      "  Closest object: 12.0 meters\n",
      "  Farthest object: 117.1 meters\n",
      "  Average speed (moving): 505.2 km/h\n",
      "  Max speed: 6010.1 km/h\n",
      "\n",
      "Tracked Objects: 57\n",
      "======================================================================\n",
      "\n",
      "üìè Distance Estimation: Pinhole Camera Model\n",
      "Current FOCAL_LENGTH_PX = 1000\n",
      "Calibrate for accurate results - see README for instructions\n",
      "======================================================================\n",
      "\n",
      "Stopped by user\n",
      "\n",
      "======================================================================\n",
      "‚úì Video processing complete!\n",
      "======================================================================\n",
      "Total frames processed: 791\n",
      "Total detections: 1510\n",
      "\n",
      "Output files:\n",
      "  Video: f:\\skills-copilot-codespaces-vscode\\thesis\\all code\\runs\\detect\\distance_tracking\\annotated_video.mp4\n",
      "  CSV:   f:\\skills-copilot-codespaces-vscode\\thesis\\all code\\runs\\detect\\distance_tracking\\detections_with_distance.csv\n",
      "\n",
      "Detection Summary by Class:\n",
      "               Detections  Avg Confidence  Avg Distance (m)  Avg Speed (km/h)\n",
      "class                                                                        \n",
      "auto_rickshaw          83            0.30         71.040001            126.11\n",
      "bus                     3            0.20         12.970000              6.80\n",
      "car                  1324            0.70         43.090000            550.26\n",
      "micro_bus              31            0.46         23.150000             46.31\n",
      "motorcycle             41            0.34         77.199997             70.46\n",
      "person                 24            0.27         31.760000             51.06\n",
      "rickshaw                4            0.19         76.970001             38.51\n",
      "\n",
      "Overall Stats:\n",
      "  Average confidence: 0.650\n",
      "  Average distance: 45.0 meters\n",
      "  Closest object: 12.0 meters\n",
      "  Farthest object: 117.1 meters\n",
      "  Average speed (moving): 505.2 km/h\n",
      "  Max speed: 6010.1 km/h\n",
      "\n",
      "Tracked Objects: 57\n",
      "======================================================================\n",
      "\n",
      "üìè Distance Estimation: Pinhole Camera Model\n",
      "Current FOCAL_LENGTH_PX = 1000\n",
      "Calibrate for accurate results - see README for instructions\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# ------------------------\n",
    "# GPU check\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ------------------------\n",
    "# Load YOLO model (your trained model)\n",
    "model_path = \"f:/skills-copilot-codespaces-vscode/thesis/runs/detect/rsud20k_yolo114/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "model.to(device)\n",
    "print(f\"‚úì Loaded YOLO model from: {model_path}\")\n",
    "print(f\"Model classes: {model.names}\")\n",
    "\n",
    "# ------------------------\n",
    "# CLASS NAME REMAPPING\n",
    "CLASS_REMAP = {\n",
    "    'person': 'person',\n",
    "    'rickshaw': 'rickshaw',\n",
    "    'rickshaw_van': 'rickshaw_van',\n",
    "    'auto_rickshaw': 'auto_rickshaw',\n",
    "    'truck': 'truck',\n",
    "    'pickup_truck': 'pickup_truck',\n",
    "    'private_car': 'car',\n",
    "    'motorcycle': 'motorcycle',\n",
    "    'bicycle': 'bicycle',\n",
    "    'bus': 'bus',\n",
    "    'micro_bus': 'micro_bus',\n",
    "    'covered_van': 'covered_van',\n",
    "    'human_hauler': 'human_hauler',\n",
    "    'motorbike': 'motorcycle',\n",
    "    'car': 'car',\n",
    "}\n",
    "\n",
    "# REAL-WORLD OBJECT SIZES (average dimensions in meters)\n",
    "OBJECT_REAL_SIZES = {\n",
    "    'person': {'width': 0.5, 'height': 1.7, 'length': 0.3},\n",
    "    'rickshaw': {'width': 1.2, 'height': 1.8, 'length': 2.5},\n",
    "    'rickshaw_van': {'width': 1.5, 'height': 2.0, 'length': 3.0},\n",
    "    'auto_rickshaw': {'width': 1.3, 'height': 1.6, 'length': 2.8},\n",
    "    'truck': {'width': 2.5, 'height': 3.5, 'length': 8.0},\n",
    "    'pickup_truck': {'width': 2.0, 'height': 2.2, 'length': 5.5},\n",
    "    'car': {'width': 1.8, 'height': 1.5, 'length': 4.5},\n",
    "    'motorcycle': {'width': 0.8, 'height': 1.2, 'length': 2.2},\n",
    "    'bicycle': {'width': 0.6, 'height': 1.1, 'length': 1.8},\n",
    "    'bus': {'width': 2.5, 'height': 3.2, 'length': 12.0},\n",
    "    'micro_bus': {'width': 2.0, 'height': 2.5, 'length': 6.0},\n",
    "    'covered_van': {'width': 2.0, 'height': 2.3, 'length': 5.0},\n",
    "    'human_hauler': {'width': 1.5, 'height': 2.0, 'length': 3.5},\n",
    "}\n",
    "\n",
    "# ------------------------\n",
    "# CAMERA CALIBRATION - PINHOLE CAMERA MODEL\n",
    "# ------------------------\n",
    "FOCAL_LENGTH_PX = 1000  # Focal length in pixels\n",
    "FRAME_RATE_SAMPLES = 5  # Frames to average for speed\n",
    "\n",
    "print(f\"\\nCamera calibration:\")\n",
    "print(f\"  Focal length: {FOCAL_LENGTH_PX} pixels\")\n",
    "print(f\"  Speed averaging: {FRAME_RATE_SAMPLES} frames\")\n",
    "\n",
    "# ------------------------\n",
    "# Video Setup\n",
    "video_path = r\"F:\\skills-copilot-codespaces-vscode\\thesis\\Night Driving Seoul City _ Gangnam and Expressway with Chill Lofi Hiphop Beats POV 4K HDR.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"\\nVideo Info:\")\n",
    "print(f\"  Resolution: {width}x{height}\")\n",
    "print(f\"  FPS: {fps}\")\n",
    "print(f\"  Total Frames: {total_frames}\")\n",
    "print(f\"  Duration: {total_frames/fps:.1f} seconds\")\n",
    "\n",
    "DELTA_TIME = 1.0 / fps\n",
    "\n",
    "# Display settings\n",
    "display_width = 1280\n",
    "display_height = int(height * (display_width / width))\n",
    "\n",
    "# ------------------------\n",
    "# Output setup\n",
    "output_dir = Path(\"runs/detect/distance_tracking\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_video = output_dir / \"annotated_video.mp4\"\n",
    "output_csv = output_dir / \"detections_with_distance.csv\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(str(output_video), fourcc, fps, (width, height))\n",
    "\n",
    "# ------------------------\n",
    "# Detection settings\n",
    "CONFIDENCE_THRESHOLD = 0.15\n",
    "IOU_THRESHOLD = 0.3\n",
    "IMAGE_SIZE = 1280\n",
    "MAX_TRACKING_DISTANCE = 150\n",
    "\n",
    "print(f\"\\nDetection settings:\")\n",
    "print(f\"  Confidence: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"  IoU: {IOU_THRESHOLD}\")\n",
    "print(f\"  Image size: {IMAGE_SIZE}px\")\n",
    "\n",
    "# ------------------------\n",
    "# Tracking variables\n",
    "detection_data = []\n",
    "frame_id = 0\n",
    "tracked_objects = {}\n",
    "next_object_id = 0\n",
    "\n",
    "def estimate_distance(bbox_width, bbox_height, object_class, focal_length):\n",
    "    \"\"\"\n",
    "    Pinhole camera model: Distance = (Real_Size √ó Focal_Length) / Pixel_Size\n",
    "    \"\"\"\n",
    "    if object_class not in OBJECT_REAL_SIZES:\n",
    "        return None\n",
    "    \n",
    "    real_width = OBJECT_REAL_SIZES[object_class]['width']\n",
    "    real_height = OBJECT_REAL_SIZES[object_class]['height']\n",
    "    \n",
    "    distance_from_width = (real_width * focal_length) / bbox_width if bbox_width > 0 else 999\n",
    "    distance_from_height = (real_height * focal_length) / bbox_height if bbox_height > 0 else 999\n",
    "    \n",
    "    distance = (distance_from_width + distance_from_height) / 2.0\n",
    "    return distance\n",
    "\n",
    "def find_closest_tracked_object(center_x, center_y, object_class, frame_num):\n",
    "    \"\"\"Find closest previously tracked object of same class\"\"\"\n",
    "    min_distance = float('inf')\n",
    "    closest_id = None\n",
    "    \n",
    "    for obj_id, obj_data in tracked_objects.items():\n",
    "        if obj_data['class'] != object_class:\n",
    "            continue\n",
    "        \n",
    "        if len(obj_data['positions']) > 0:\n",
    "            last_x, last_y, last_frame = obj_data['positions'][-1]\n",
    "            \n",
    "            if frame_num - last_frame > 10:\n",
    "                continue\n",
    "            \n",
    "            dist = np.sqrt((center_x - last_x)**2 + (center_y - last_y)**2)\n",
    "            \n",
    "            if dist < min_distance and dist < MAX_TRACKING_DISTANCE:\n",
    "                min_distance = dist\n",
    "                closest_id = obj_id\n",
    "    \n",
    "    return closest_id\n",
    "\n",
    "def calculate_speed(obj_data, current_distance, current_frame):\n",
    "    \"\"\"\n",
    "    Calculate real-world speed using 3D displacement\n",
    "    \"\"\"\n",
    "    if len(obj_data['positions']) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    positions = obj_data['positions'][-FRAME_RATE_SAMPLES:]\n",
    "    distances = obj_data['distances'][-FRAME_RATE_SAMPLES:]\n",
    "    \n",
    "    if len(positions) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    first_x, first_y, first_frame = positions[0]\n",
    "    last_x, last_y, last_frame = positions[-1]\n",
    "    \n",
    "    first_distance = distances[0]\n",
    "    last_distance = distances[-1]\n",
    "    \n",
    "    # Convert pixel movement to meters\n",
    "    avg_distance = (first_distance + last_distance) / 2.0\n",
    "    meters_per_pixel = avg_distance / FOCAL_LENGTH_PX\n",
    "    \n",
    "    lateral_displacement_x = (last_x - first_x) * meters_per_pixel\n",
    "    lateral_displacement_y = (last_y - first_y) * meters_per_pixel\n",
    "    depth_displacement = last_distance - first_distance\n",
    "    \n",
    "    # Total 3D displacement\n",
    "    total_displacement = np.sqrt(\n",
    "        lateral_displacement_x**2 + \n",
    "        lateral_displacement_y**2 + \n",
    "        depth_displacement**2\n",
    "    )\n",
    "    \n",
    "    frames_elapsed = last_frame - first_frame\n",
    "    time_elapsed = frames_elapsed * DELTA_TIME\n",
    "    \n",
    "    if time_elapsed == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    speed_ms = total_displacement / time_elapsed\n",
    "    speed_kmh = speed_ms * 3.6\n",
    "    \n",
    "    return abs(speed_kmh)\n",
    "\n",
    "print(\"\\nProcessing video...\")\n",
    "print(\"Press 'q' to stop early\\n\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_id += 1\n",
    "    \n",
    "    # YOLO detection with improved settings\n",
    "    results = model(\n",
    "        frame, \n",
    "        conf=CONFIDENCE_THRESHOLD,\n",
    "        iou=IOU_THRESHOLD,\n",
    "        imgsz=IMAGE_SIZE,\n",
    "        verbose=False,\n",
    "        agnostic_nms=False,\n",
    "        max_det=300\n",
    "    )[0]\n",
    "    \n",
    "    current_detections = []\n",
    "    \n",
    "    # Process detections\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = float(box.conf[0])\n",
    "        cls = int(box.cls[0])\n",
    "        original_label = results.names[cls]\n",
    "        \n",
    "        label = CLASS_REMAP.get(original_label, original_label)\n",
    "        \n",
    "        cx = (x1 + x2) / 2\n",
    "        cy = (y1 + y2) / 2\n",
    "        bbox_width = x2 - x1\n",
    "        bbox_height = y2 - y1\n",
    "        \n",
    "        if bbox_width < 10 or bbox_height < 10:\n",
    "            continue\n",
    "        \n",
    "        distance = estimate_distance(bbox_width, bbox_height, label, FOCAL_LENGTH_PX)\n",
    "        \n",
    "        if distance is None or distance > 200:\n",
    "            continue\n",
    "        \n",
    "        current_detections.append({\n",
    "            'cx': cx,\n",
    "            'cy': cy,\n",
    "            'class': label,\n",
    "            'original_label': original_label,\n",
    "            'conf': conf,\n",
    "            'bbox': (x1, y1, x2, y2),\n",
    "            'distance': distance,\n",
    "            'bbox_width': bbox_width,\n",
    "            'bbox_height': bbox_height\n",
    "        })\n",
    "    \n",
    "    # Track objects and calculate speeds\n",
    "    for det in current_detections:\n",
    "        cx, cy = det['cx'], det['cy']\n",
    "        label = det['class']\n",
    "        distance = det['distance']\n",
    "        \n",
    "        obj_id = find_closest_tracked_object(cx, cy, label, frame_id)\n",
    "        \n",
    "        if obj_id is None:\n",
    "            obj_id = next_object_id\n",
    "            next_object_id += 1\n",
    "            tracked_objects[obj_id] = {\n",
    "                'class': label,\n",
    "                'positions': [],\n",
    "                'distances': [],\n",
    "                'speeds': []\n",
    "            }\n",
    "        \n",
    "        tracked_objects[obj_id]['positions'].append((cx, cy, frame_id))\n",
    "        tracked_objects[obj_id]['distances'].append(distance)\n",
    "        \n",
    "        speed_kmh = calculate_speed(tracked_objects[obj_id], distance, frame_id)\n",
    "        tracked_objects[obj_id]['speeds'].append(speed_kmh)\n",
    "        \n",
    "        det['speed_kmh'] = speed_kmh\n",
    "        det['object_id'] = obj_id\n",
    "    \n",
    "    # Draw detections with distance and speed\n",
    "    for det in current_detections:\n",
    "        x1, y1, x2, y2 = det['bbox']\n",
    "        label = det['class']\n",
    "        conf = det['conf']\n",
    "        distance = det['distance']\n",
    "        speed_kmh = det['speed_kmh']\n",
    "        \n",
    "        # Color based on distance\n",
    "        if distance < 10:\n",
    "            color = (0, 0, 255)  # Red - close\n",
    "        elif distance < 25:\n",
    "            color = (0, 165, 255)  # Orange - medium\n",
    "        else:\n",
    "            color = (0, 255, 0)  # Green - far\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 3)\n",
    "        \n",
    "        # Class label\n",
    "        label_text = f\"{label}: {conf:.2f}\"\n",
    "        (text_width, text_height), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)-text_height-10), (int(x1)+text_width+10, int(y1)), color, -1)\n",
    "        cv2.putText(frame, label_text, (int(x1)+5, int(y1)-5), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        \n",
    "        # Distance\n",
    "        distance_text = f\"Dist: {distance:.1f}m\"\n",
    "        (dist_width, dist_height), _ = cv2.getTextSize(distance_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "        cv2.rectangle(frame, (int(x1), int(y2)+5), (int(x1)+dist_width+10, int(y2)+dist_height+15), (255, 165, 0), -1)\n",
    "        cv2.putText(frame, distance_text, (int(x1)+5, int(y2)+dist_height+10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        # Speed (only if moving)\n",
    "        if speed_kmh > 1.0:\n",
    "            speed_text = f\"Speed: {speed_kmh:.1f} km/h\"\n",
    "            (speed_width, speed_height), _ = cv2.getTextSize(speed_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "            cv2.rectangle(frame, (int(x1), int(y2)+dist_height+20), \n",
    "                         (int(x1)+speed_width+10, int(y2)+dist_height+speed_height+30), (0, 0, 255), -1)\n",
    "            cv2.putText(frame, speed_text, (int(x1)+5, int(y2)+dist_height+speed_height+25), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        # Store data\n",
    "        detection_data.append({\n",
    "            'frame': frame_id,\n",
    "            'time_sec': frame_id / fps,\n",
    "            'object_id': det['object_id'],\n",
    "            'class': label,\n",
    "            'original_class': det['original_label'],\n",
    "            'confidence': conf,\n",
    "            'x1': x1,\n",
    "            'y1': y1,\n",
    "            'x2': x2,\n",
    "            'y2': y2,\n",
    "            'center_x': det['cx'],\n",
    "            'center_y': det['cy'],\n",
    "            'distance_meters': distance,\n",
    "            'speed_kmh': speed_kmh,\n",
    "            'bbox_width': det['bbox_width'],\n",
    "            'bbox_height': det['bbox_height']\n",
    "        })\n",
    "    \n",
    "    # Frame info\n",
    "    cv2.rectangle(frame, (5, 5), (450, 95), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Frame: {frame_id}/{total_frames}\", (10, 30), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"Objects: {len(current_detections)}\", (10, 60), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"Tracked: {len(tracked_objects)}\", (10, 90), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    # Write output\n",
    "    out.write(frame)\n",
    "    \n",
    "    # Display\n",
    "    display_frame = cv2.resize(frame, (display_width, display_height))\n",
    "    cv2.imshow(\"Object Detection - Distance & Speed (Press Q to quit)\", display_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"\\nStopped by user\")\n",
    "        break\n",
    "    \n",
    "    # Progress\n",
    "    if frame_id % 30 == 0:\n",
    "        progress = (frame_id / total_frames) * 100\n",
    "        num_detections = len(current_detections)\n",
    "        if num_detections > 0:\n",
    "            avg_dist = np.mean([d['distance'] for d in current_detections])\n",
    "            avg_conf = np.mean([d['conf'] for d in current_detections])\n",
    "            print(f\"Progress: {progress:.1f}% ({frame_id}/{total_frames}) - Objects: {num_detections} - Avg Conf: {avg_conf:.2f} - Avg Dist: {avg_dist:.1f}m\")\n",
    "        else:\n",
    "            print(f\"Progress: {progress:.1f}% ({frame_id}/{total_frames})\")\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save CSV\n",
    "df = pd.DataFrame(detection_data)\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì Video processing complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total frames processed: {frame_id}\")\n",
    "print(f\"Total detections: {len(detection_data)}\")\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  Video: {output_video.absolute()}\")\n",
    "print(f\"  CSV:   {output_csv.absolute()}\")\n",
    "\n",
    "if len(detection_data) > 0:\n",
    "    print(f\"\\nDetection Summary by Class:\")\n",
    "    class_summary = df.groupby('class').agg({\n",
    "        'object_id': 'count',\n",
    "        'confidence': 'mean',\n",
    "        'distance_meters': 'mean',\n",
    "        'speed_kmh': lambda x: x[x > 1.0].mean() if len(x[x > 1.0]) > 0 else 0\n",
    "    }).round(2)\n",
    "    class_summary.columns = ['Detections', 'Avg Confidence', 'Avg Distance (m)', 'Avg Speed (km/h)']\n",
    "    print(class_summary.to_string())\n",
    "    \n",
    "    print(f\"\\nOverall Stats:\")\n",
    "    print(f\"  Average confidence: {df['confidence'].mean():.3f}\")\n",
    "    print(f\"  Average distance: {df['distance_meters'].mean():.1f} meters\")\n",
    "    print(f\"  Closest object: {df['distance_meters'].min():.1f} meters\")\n",
    "    print(f\"  Farthest object: {df['distance_meters'].max():.1f} meters\")\n",
    "    \n",
    "    moving_objects = df[df['speed_kmh'] > 1.0]\n",
    "    if len(moving_objects) > 0:\n",
    "        print(f\"  Average speed (moving): {moving_objects['speed_kmh'].mean():.1f} km/h\")\n",
    "        print(f\"  Max speed: {moving_objects['speed_kmh'].max():.1f} km/h\")\n",
    "    \n",
    "    print(f\"\\nTracked Objects: {len(tracked_objects)}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìè Distance Estimation: Pinhole Camera Model\")\n",
    "print(f\"Current FOCAL_LENGTH_PX = {FOCAL_LENGTH_PX}\")\n",
    "print(\"Calibrate for accurate results - see README for instructions\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
